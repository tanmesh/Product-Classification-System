{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('my_data.csv')\n",
    "df.drop(['entry_id', 'pos1', 'pos2'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463068"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['bread1'].values.tolist()\n",
    "y = df['bread2'].values.tolist()\n",
    "corpus = x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "926136"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tanmesh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "sw_list = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all the special characters\n",
    "def unique_list(l):\n",
    "    ulist = []\n",
    "    [ulist.append(x) for x in l if x not in ulist]\n",
    "    return ulist\n",
    "\n",
    "def preprocess(x):\n",
    "    s = ''\n",
    "    x = re.sub('\\W+', ' ', x)\n",
    "    for data in x:\n",
    "        if data not in sw_list:\n",
    "            s += \" \"+data\n",
    "    s = s[1:]\n",
    "    s = '  '.join(unique_list(s.split()))\n",
    "    return x\n",
    "\n",
    "new_corpus = []\n",
    "for data in corpus :\n",
    "    data = str(data).lower()\n",
    "    new_corpus.append(preprocess(data))\n",
    "\n",
    "corpus = new_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clothing accessories men winterwear jackets '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy data in \"latest_file.csv\"\n",
    "with open('latest_file.csv', 'w') as f:\n",
    "    i = 0\n",
    "    for data in corpus :\n",
    "        if i < len(corpus)/10000 :\n",
    "            f.write(\"%s\\n\" % data)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('latest_file.csv', names = ['breads', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>breads</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clothing accessories men winterwear jackets</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clothing accessories men winterwear sweatshirt...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shoes handbags shoes men s shoes men running s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>home entertainment audio video tv headphones e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>home kitchen small kitchen appliances mixer gr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              breads  label\n",
       "0       clothing accessories men winterwear jackets     NaN\n",
       "1  clothing accessories men winterwear sweatshirt...    NaN\n",
       "2  shoes handbags shoes men s shoes men running s...    NaN\n",
       "3  home entertainment audio video tv headphones e...    NaN\n",
       "4  home kitchen small kitchen appliances mixer gr...    NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_corpus = []\n",
    "for data in corpus :\n",
    "    token_corpus.append(nltk.word_tokenize(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clothing', 'accessories', 'men', 'winterwear', 'jackets']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "from gensim import models, similarities, corpora\n",
    "import gensim.models.word2vec as w2v\n",
    "import multiprocessing\n",
    "\n",
    "num_features = 300\n",
    "min_word_count = 1\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "context_size = 3\n",
    "downsampling = 1e-3\n",
    "seed = 1\n",
    "\n",
    "model = w2v.Word2Vec( \n",
    "    sg=1,\n",
    "    seed=seed,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context_size,\n",
    "    sample=downsampling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(token_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec vocabulary length: 19930\n"
     ]
    }
   ],
   "source": [
    "print(\"Word2Vec vocabulary length:\", len(model.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4694730, 7500546)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(token_corpus, len(model.wv.vocab), epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = w2v.Word2Vec.load(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import manifold\n",
    "tsne = sklearn.manifold.TSNE(n_components=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "all_word_vectors_matrix = model.wv.syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_word_vectors_matrix_2d = tsne.fit_transform(all_word_vectors_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = pd.DataFrame(\n",
    "    [\n",
    "        (word, coords[0], coords[1])\n",
    "        for word, coords in [\n",
    "            (word, all_word_vectors_matrix_2d[model.wv.vocab[word].index])\n",
    "            for word in model.wv.vocab\n",
    "        ]\n",
    "    ],\n",
    "    columns=[\"word\", \"x\", \"y\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points.plot.scatter(\"x\", \"y\", s=10, figsize=(20, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_region(x_bounds, y_bounds):\n",
    "    slice = points[\n",
    "        (x_bounds[0] <= points.x) &\n",
    "        (points.x <= x_bounds[1]) & \n",
    "        (y_bounds[0] <= points.y) &\n",
    "        (points.y <= y_bounds[1])\n",
    "    ]\n",
    "    \n",
    "    ax = slice.plot.scatter(\"x\", \"y\", s=35, figsize=(10, 8))\n",
    "    for i, point in slice.iterrows():\n",
    "        ax.text(point.x + 0.005, point.y + 0.005, point.word, fontsize=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_region(x_bounds=(-400.0, -20), y_bounds=(-0.5, -0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_region(x_bounds=(0, 0.2), y_bounds=(4, 4.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(\"clothing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(\"mobile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar('furniture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar_to_cloth = []\n",
    "# tmp_list = model.most_similar('clothing')\n",
    "# for data in tmp_list :\n",
    "#     similar_to_cloth.append(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar_to_cloth.append('clothing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in range(len(train_df)) :\n",
    "#     cnt = False\n",
    "    \n",
    "#     for data in similar_to_cloth :\n",
    "#             if data in str(train_df['breads'][row]) :\n",
    "#                 cnt = True\n",
    "            \n",
    "#     if cnt == False :\n",
    "#         train_df['label'][row] = 'not clothing'\n",
    "#     else :\n",
    "#         train_df['label'][row] = 'clothing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train_df.to_csv(r'aarey.csv')\n",
    "# len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn import svm\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# x = np.array(train_df.drop(['label'], axis = 1))\n",
    "# y = np.array(train_df.drop(['breads'], axis = 1))\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "\n",
    "# clf = svm.SVC(kernel = 'linear', gamma = 1)\n",
    "# clf.fit(x_train, y_train)\n",
    "\n",
    "# accuracy = clf.score(x_test, x_test)\n",
    "# print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
